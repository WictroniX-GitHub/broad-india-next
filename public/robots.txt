# Robots.txt for BROAD India website
# This file tells search engines which pages they can crawl

# Allow all web crawlers to access all content
User-agent: *
Allow: /

# Explicitly allow important pages and sections
Allow: /blogs/
Allow: /articles/
Allow: /vapour-absorption-chiller/
Allow: /power-efficient-chiller/
Allow: /cchp-systems/
Allow: /about
Allow: /contact-us
Allow: /installations

# Disallow crawling of private or unnecessary files
Disallow: /api/
Disallow: /_next/
Disallow: /admin/
Disallow: /.well-known/
Disallow: /tmp/
Disallow: /*.json$
Disallow: /files/

# Allow specific important crawlers
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp
Allow: /
Crawl-delay: 1

User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

User-agent: Baiduspider
Allow: /
Crawl-delay: 2

User-agent: YandexBot
Allow: /
Crawl-delay: 2

# Block aggressive crawlers
User-agent: SemrushBot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: MJ12bot
Disallow: /

# General crawl-delay to be respectful to server resources
Crawl-delay: 1

# Sitemap location
Sitemap: https://www.broadindia.com/sitemap.xml

# Host directive (preferred domain)
Host: https://www.broadindia.com
